# Defense-Against-Adversarial-Patch-Attacks-using-Generative-Neural-Architecture
This project aims to develop a defense strategy to mitigate adversarial patches in image classification systems. Inspired by the research "Anomaly Unveiled: Securing Image Classification against Adversarial Patch Attacks" by Nandish Chattopadhyay et al., the solution utilizes a Generative Neural Architecture (GNA) combined with a three-pipeline anomaly detection system. The process works as follows:

Comparison: Initial data comparison to detect potential anomalies.
Analysis: A thorough analysis pipeline to identify adversarial patches.
Refinement: Final refinement, neutralizing adversarial components.
The comprehensive three-step pipeline ensures robust defense by refining the data and neutralizing its ability to function as an adversarial patch, enhancing the security and accuracy of image classification.
